{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "After browsing the various datasets we found on the world wide web, looking at old projects and brainstorming we decided that we wanted to look into movies. We decided to try and make a movie recommendation engine by using networking and text analysis. The initial idea was to find a dataset which provided waist amount of information about movies. Furthermore we wanted to find moviescripts and reviews for each movie in the dataset and do text analysis like sentiment analysis and similirity measures on these texts. The goal was to combine these information and create a recommendation engine where the user could insert a name of a movie that he liked and our algorithm would find and output movies that where similar to the inserted movie. \n",
    "    \n",
    "Our goal was clear from the get go. We needed to find a dataset that fulfilled our requirements. We found a dataset available on Kaggle.com that was a good match for us. The dataset isn’t quite big, around 50 mb, but it contains a lot of information. It includes close to 20 properties for around 5000 movies. \n",
    "\n",
    "In the following section we will discuss each dataset that we found, how we manage to gather it and what the purpose behind it was. \n",
    "\n",
    "\n",
    "## Basic stats\n",
    "\n",
    "### TMDB 5000 Movie dataset \n",
    "\n",
    "This was our central dataset in our analysis. This dataset fulfilled our requirements. It contain waiste amount of data and all of the information is gather from the site [TMDb.com](https://www.themoviedb.org) (The movie database). The database can be found and downloaded from this [website](https://www.kaggle.com/tmdb/tmdb-movie-metadata) \n",
    "\n",
    "** Basic stats **\n",
    "\n",
    " - The dataset comes in two files: \n",
    "     - tmdb_5000_credits.csv 40 mb with\n",
    "     - tmdb_5000_movies.csv.\n",
    " - The movies in the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "All the information is gathered from the site TMDb.com (The Movie Database). The movies span years from 1916-2017.\n",
    "    \n",
    "    \n",
    "The dataset isn’t quite big, around 50 mb, but it contains a lot of information. It includes close to 20 properties for 5000 movies, for example  cast, crew, production company, revenue, budget, genre, keywords. All the information is gathered from the site TMDb.com (The Movie Database). The movies span years from 1916-2017.\n",
    "    \n",
    "    While this dataset has a lot to offer we decided to gather a bit more data ourselves. We had user rating from TMDb but we also wanted to look at user ratings from IMDb (Internet Movie Database) as they have much more votes and thus are more realistic. We used simple scraping with ‘urllib’ and regular expression to get the ratings from IMDb. Now we wanted to add some text analysis to our recommendation engine, to do that we decided to find some movie scripts and see if we could find some interesting connections between the movie data we had and the movie’s scripts and also use the scripts to find similarities. ***Grétar, hvernig sóttiru scripts???***. To add even more to our text analysis portion we decided to look at some user reviews. We found a data set that contained a 100.000 user reviews from IMDb on some 14.000 movies. The dataset is available at: http://ai.stanford.edu/~amaas/data/sentiment/. The dataset only contained the movie’s IMDb ID which we didn’t have so we again needed to do some scraping, this time we used the IMDb IDs to get the title of the movies so we could link them to our TMDb dataset. That resulted in around 14.000 reviews for around 1.200 movies that were common with our 5.000 gotten from the TMDb dataset. The scripts and reviews were only applicable to a subset of our big movie dataset. This was a problem as we didn’t want to make a recommendation engine that only contained a bit more than a 1.000 movies. We however did a thorough analysis of the scripts to make a proof of concept that it could’ve been used as input into our recommendation engine. We after that decided to get more text data. We thought about what we could use other than scripts and reviews to try and find similarities between movies and ended up with trying to use the movie’s storyline. This was data we didn’t have, so once again we turned to scraping. We had the help of a library called ‘beautifulsoup’. After this we finally had some nice juicy text to use in our engine.\n",
    "\n",
    "The end goal was a movie recommendation engine where a user could write in a movie and we would recommend similar movies the user might like. We wanted to function quite well and even use it ourselves. We’ve all spent a lot of time in our lives trying to decide on a movie to watch. The recommendation engine will use shortest path calculations on a network that we design. There will be multiple things affecting the links between movies, e.g. cast of movies, keywords, genres, directors, IMDb ratings and similarities in storylines. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
