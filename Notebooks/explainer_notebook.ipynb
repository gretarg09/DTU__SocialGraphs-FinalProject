{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "After browsing the various datasets we found on the world wide web, looking at old projects and brainstorming we decided that we wanted to look into movies. We decided to try and make a movie recommendation engine by using networking and text analysis. The initial idea was to find a dataset which provided waist amount of information about movies. Furthermore we wanted to find moviescripts and reviews for each movie in the dataset and do text analysis like sentiment analysis and similirity measures on these texts. The goal was to combine these information and create a recommendation engine where the user could insert a name of a movie that he liked and our algorithm would find and output movies that where similar to the inserted movie. \n",
    "    \n",
    "Our goal was clear from the get go. We needed to find a dataset that fulfilled our requirements. We found a dataset available on Kaggle.com that was a good match for us. The dataset isn’t quite big, around 50 mb, but it contains a lot of information. It includes close to 20 properties for around 5000 movies. \n",
    "\n",
    "In the following section we will discuss each dataset that we found, how we manage to gather it and what the purpose behind it was. \n",
    "\n",
    "\n",
    "## Basic stats\n",
    "\n",
    "### TMDB 5000 Movie dataset \n",
    "\n",
    "This was our central dataset in our analysis. This dataset fulfilled our requirements. It contain waiste amount of data and all of the information is gather from the site [TMDb.com](https://www.themoviedb.org) (The movie dataset). The dataset can be found and downloaded from this [website](https://www.kaggle.com/tmdb/tmdb-movie-metadata) \n",
    "\n",
    "** Basic stats **\n",
    "\n",
    " - The dataset comes in two files: \n",
    "     - **tmdb_5000_credits.csv**, the size is 40 MB and the variables in this file are the following:\n",
    "         - *movie_id* : the uniq id of the movie\n",
    "         - *title* : the name of the movie\n",
    "         - *crew* : info about the crew members of the movie \n",
    "         - *cast* : info about the cast member of the movie\n",
    "     - **tmdb_5000_movies.csv**, the size is 5.7 MB and the variables in this file are the following:\n",
    "         - *movie_id* : the uniq id of the movie\n",
    "         - *original_language*: we did not use this variable  \n",
    "         - *title* : the name of the movie\n",
    "         - *genres* : there are 17 movies genres in this dataset.\n",
    "         - *tagline* : was not used \n",
    "         - *production_countries*: was not used\n",
    "         - *production_companies* : the company/companies that produced the movie \n",
    "         - *popularity* :  \n",
    "         - *spoken_languages* : was not used \n",
    "         - *original_title* : was not used \n",
    "         - *release_date* :  the data when the movie was released \n",
    "         - *runtime* : the total length of the movie \n",
    "         - *vote_count* : how many users graded the movie\n",
    "         - *vote_average* : the average grade that the movie got, we did not use this like we will come back to here down below \n",
    "         - *status* : was not used  \n",
    "         - *revenue* : The total earnings of the movie.\n",
    "         - *overview* : A small description about the movie, We did not use this like we will come back to here down below\n",
    "         - *budget* : The amount spent on making the movie\n",
    "         - *keywords* : Set of words that is explanatory of the movie\n",
    "         - *homepage* :  was not used\n",
    " - The dataset contains information about 4800 movies\n",
    " - The movies span years from 1916-2017.\n",
    "\n",
    "While this dataset has a lot to offer we decided to gather a bit more data ourselves. We had user rating and storyline (called overview in the tmdb databse) from TMDb but we also wanted to look at user ratings and the storyline from IMDb (Internet Movie Database) as they have much more votes and thus are more realistic.\n",
    "\n",
    "** Data cleaning and preprocessing **\n",
    "\n",
    "There where couple of movies in the database that lacked some informations. What we did is simply to check whether all of the data that we needed for each analysis was there and if not we ignored the movie from the analysis. This dataset is quite good and there are not many movies that lack data therefore we did not need to do much of an preprocessing of the dataset. \n",
    "\n",
    "**NOTE:** The Kaggle dataset also contains some TV shows, but they are very few and we did not consider it to be a problem for our analysis and therefore we did not delete them from the dataset. Also it would be quite hard to go over all of the 4800 items in the dataset and figure out what is a movie and what is a tv-show. \n",
    "\n",
    "### User rating and storyline from IMDB \n",
    "\n",
    "We used the a  library called ‘beautifulsoup’ and regex to scrape the [IMDb website](http://www.imdb.com/) to gather the user rating and the storyline for each movie in our kaggle dataset. The code that was used to accomplish this can be found in the [Get_additional_data notebook](https://github.com/gretarg09/Dtu-SocialGraphs-FinalProject/blob/master/Notebooks/Get_Additional_Data.ipynb) which can be found by clicking on the link. This produced two files:\n",
    "\n",
    "[imdb-score.json](https://github.com/gretarg09/Dtu-SocialGraphs-FinalProject/blob/master/Data/imdb-score.json) : This file contains the IMDb rating of the movies in our Kaggle dataset\n",
    "\n",
    "\n",
    "[imdb-score.json](https://github.com/gretarg09/Dtu-SocialGraphs-FinalProject/blob/master/Data/imdb-storyline.json) :  This file contains the IMDb storyline of the movies in our Kaggle dataset\n",
    "\n",
    "By scraping and manually picking in the IMDb storyline and the IMDb rating for those movies that have non unicode caracters in their names we manage to gather information for all movies in or kaggle dataset except five. The way we handle that in our analysis is by simply ignoring the movies that we did not manage to get any IMDb information about when the data for those movies where needed. \n",
    "    \n",
    "\n",
    "### Manuscripts\n",
    "\n",
    "We wanted to add some text analysis to our recommendation engine, to do that we decided to find some movie manuscripts and see if we could find some interesting connections between the movie data we had and the movie’s scripts and also use the scripts to find similarities. We found a script online that downloadeds all the manuscripts that can be found on the website [The Internet Movie Script Database (IMSDb)](http://www.imsdb.com/). This code was taken from [this github repository](https://github.com/j2kun/imsdb_download_all_scripts) and adapted to our needs. Our code can be found in in the [Get_additional_data notebook](https://github.com/gretarg09/Dtu-SocialGraphs-FinalProject/blob/master/Notebooks/Get_Additional_Data.ipynb). The code uses the modules BeautifulSoup and urllip to scrape the IMSDb website and download the files. \n",
    "\n",
    "The total amount of manuscripts in IMSDb website is only 1116 manuscripts and the intersection with our kaggle dataset is 715 manuscripts. Therefore we only manage to find manuscript for 715 movies out of the 4800 movies that we have in our dataset. \n",
    "\n",
    "The total size of the manuscript dataset is 232,6 MB and can be downloaded [here](https://github.com/gretarg09/Dtu-SocialGraphs-FinalProject/tree/master/Data)\n",
    "\n",
    "\n",
    "### Users Reviews\n",
    "\n",
    "To add even more to our text analysis portion we decided to look at some user reviews. We found a data set that contained a 100.000 user reviews from IMDb on some 14.000 movies. The dataset is available at: http://ai.stanford.edu/~amaas/data/sentiment/. The dataset only contained the movie’s IMDb ID which we didn’t have so we again needed to do some scraping, this time we used the IMDb IDs to get the title of the movies so we could link them to our TMDb dataset. Here we only used urllib and regex to get the job done. \n",
    "\n",
    "That resulted in around 14.000 reviews for around 1.200 movies that were common with our 4800 gotten from the Kaggle dataset. The scripts and reviews were only applicable to a subset of our Kaggle dataset.\n",
    "\n",
    "\n",
    "The code where we gather the reviews can be found in the [Sentiment_reviews notebook](https://github.com/gretarg09/Dtu-SocialGraphs-FinalProject/blob/master/Notebooks/Sentiment_reviews.ipynb) which can be found by clicking the link. \n",
    "\n",
    "This dataset was to big to include on github but the data can be downloaded from this [website](http://ai.stanford.edu/~amaas/data/sentiment/), like we mentioned here above and the size of the dataset is 220 MB\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools, Theory and Analysis\n",
    "\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "\n",
    "We are all huge movie fans and therefore we had a lot of fun doing this project. Therefore we did a lot of analysis on the dataset like you have probably noticed. We are quite happy about our findings and we are really proud of the final version of the recommendation engine. The recommendation engine is functioning quite well and we'll definitely be using it ourselves during the christmas break when looking for movies to wath and we encourage you to try it out on the website.\n",
    "\n",
    "Although it turned out great we tried quite a lot of different things before we were satisfied. For the network part we looked at three different networks. We created a network where movies were connected if they shared a certain percentage of their keywords. We did the same for genres as well as one network where nodes were cast members and nodes were linked if the cast members had starred together in a certain number of movies. After analyzing each of the networks we decided that none of them were good enough. This resulted in us creating a fourth network which would combine the properties of the previous three. Movies were nodes and to create links to other movies we looked at multiple properties, e.g. cast members, keywords, genres, directors and similarities in storyline. After links have been created and we’re in the process of recommending we also look at IMDb ratings. \n",
    "\n",
    "The text analysis itself went well but it ended up not being used in the recommendation engine except for the storylines of the movies. The reason for this was that the data we had for text analysis, ~14.000 reviews and ~1.000 movie scripts, only applied to a subset of our 4800 movies. We didn’t want to make the number of movies that we could recommend less than it was at the beginning. We did a lot of text analysis and made a proof of concept that the data could’ve been used in the recommendation engine. This tells us that we could have further improved the engine by getting manuscripts for all our movies and use that as a input to further improve our recommendation engine. If not the manuscript then we could use the subtitle text and do the same analysis on those text and use the information from that to further improve our engine. \n",
    "\n",
    "Retrospect, what could have been done differently\n",
    "\n",
    "- We encountered some problems when scraping the imdb website because we where basing our scraping on the name of the movie. When we look back we should have found a way to map the tmdb ids to the imdb ids and use that mapping to find the corresponding imdb website. We encoutered some difficulties because the name of the movies cannot be considered as a unique id. To illustrate this wiht an example; Avatar is a movie that most of us know and was directed by the big James Cameron but Avatar (Avatar: The Last Airbender) is also animation movie that has an impressive imdb rating of 9.2. When we scraped the internet we actually got this movie's rating for Avatar but not the James Cameron version which was the movie that we where looking for. This did not seem to happen often and we manage to fix most if not all of the error but it took a lot of manual work and it could have been avoided by simply mapping the tmdb ids to the imdb ids. Therefore the lesson learn is to always use the unique ids when doing these kind of data gathering and analysis\n",
    "\n",
    "- Like we have mentioned multiple times here in this notebook, we failed to gather manuscripts for all movies. However the subtitle text for each movie can be found on the world wide web and in retrospect it could have been a better idea to download the subtitle text for each movie and do text analysis on that dataset. In that way we could have gathered text for each movie and used the finding to improve our recommendation engine further.  \n",
    "\n",
    "Find a way to map TMDb id to imdb id to avoid using the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAlA um þetta seinna\n",
    "\n",
    "It was clear to us that we where not able to use this in our recommendation engine because we did not have information about each movie in the dataset. We still manage to get manuscripts for 715 movies in our dataset and we decided to analyse these manuscript thoroughly with the goal of finding out if we could use these \n",
    "\n",
    "\n",
    "***Grétar, hvernig sóttiru scripts???***.  This was a problem as we didn’t want to make a recommendation engine that only contained a bit more than a 1.000 movies. We however did a thorough analysis of the scripts to make a proof of concept that it could’ve been used as input into our recommendation engine. We after that decided to get more text data. We thought about what we could use other than scripts and reviews to try and find similarities between movies and ended up with trying to use the movie’s storyline. This was data we didn’t have, so once again we turned to scraping. We had the help of a library called ‘beautifulsoup’. After this we finally had some nice juicy text to use in our engine.\n",
    "\n",
    "The end goal was a movie recommendation engine where a user could write in a movie and we would recommend similar movies the user might like. We wanted to function quite well and even use it ourselves. We’ve all spent a lot of time in our lives trying to decide on a movie to watch. The recommendation engine will use shortest path calculations on a network that we design. There will be multiple things affecting the links between movies, e.g. cast of movies, keywords, genres, directors, IMDb ratings and similarities in storylines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Grétar, hvernig sóttiru scripts???***.  This was a problem as we didn’t want to make a recommendation engine that only contained a bit more than a 1.000 movies. We however did a thorough analysis of the scripts to make a proof of concept that it could’ve been used as input into our recommendation engine. We after that decided to get more text data. We thought about what we could use other than scripts and reviews to try and find similarities between movies and ended up with trying to use the movie’s storyline. This was data we didn’t have, so once again we turned to scraping. We had the help of a library called ‘beautifulsoup’. After this we finally had some nice juicy text to use in our engine.\n",
    "\n",
    "The end goal was a movie recommendation engine where a user could write in a movie and we would recommend similar movies the user might like. We wanted to function quite well and even use it ourselves. We’ve all spent a lot of time in our lives trying to decide on a movie to watch. The recommendation engine will use shortest path calculations on a network that we design. There will be multiple things affecting the links between movies, e.g. cast of movies, keywords, genres, directors, IMDb ratings and similarities in storylines. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
